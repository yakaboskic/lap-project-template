# LAP Project Template

A template repository for developing **Lightweight Analysis Pipeline (LAP)** projects using an opinionated, workflow-based architecture that emphasizes modularity, maintainability, and atomic operations.

## 🚀 Quick Start

```bash
# Clone this template
git clone <this-repo-url> my-lap-project
cd my-lap-project

# Install dependencies with uv (much faster than pip/venv)
uv sync --no-install-project

# Configure for your system (using meta-sanity YAML format)
cp config/starter.meta.yaml config/my-project.meta.yaml
# Edit config/my-project.meta.yaml with your paths

# Generate LAP meta file from YAML
generate-meta config/my-project.meta.yaml config/my-project.meta
```
### Create the following directories
```bash
mkdir log out raw
```
These are required for LAP projects and should generally not be committed to source control. 
### Test your LAP installation with your pipeline
```bash
# Test LAP installation
perl path/to/lap/installation/trunk/bin/run.pl --meta config/my-project.meta --check

# Initialize pipeline (creates directories)
perl path/to/lap/installation/trunk/bin/run.pl --meta config/my-project.meta --init --mkdir

# Run the example pipeline
perl path/to/lap/installation/trunk/bin/run.pl --meta config/my-project.meta
```

## 📁 Repository Structure

```
├── config/                      # Pipeline configurations
│   ├── starter.cfg              # Template configuration
│   └── starter.meta.yaml        # Template meta file (YAML format)
├── src/                         # Your development code
│   ├── workflows/               # Workflow scripts (one per LAP class)
│   └── modules/                 # Reusable utility modules
├── raw/                         # Raw input data files
├── out/                         # Pipeline outputs (created by LAP)
├── log/                         # Pipeline logs (created by LAP)
├── docs/                        # Comprehensive documentation
├── examples/                    # LAP example configurations
├── pyproject.toml               # Python dependencies and project config
├── uv.lock                      # Dependency lock file (generated by uv)
└── README.md
```

## 🎯 Philosophy: Atomic Pipeline Development

This template promotes an **opinionated approach** to LAP development:

### ❌ Avoid This (Monolithic Commands)
```cfg
# BAD: Single command does everything
cmd analyze_and_plot_cmd=python big_script.py \
    !{input:--input:data} \
    --do-expensive-calculation \
    --generate-plots \
    --create-reports \
    !{output:--output:everything}
```

**Problems**: Hard to debug, can't modify plots without recalculating, not parallelizable.

### ✅ Do This (Atomic Stages)
```cfg
# GOOD: Separate atomic stages
cmd calculate_cmd=uv run src/workflows/workflow.py calculate \
    !{input:--input:data} !{output:--output:calc_results}

cmd plot_cmd=uv run src/workflows/workflow.py plot \
    !{input:--input:calc_results} !{output:--output:plots}

cmd report_cmd=uv run src/workflows/workflow.py report \
    !{input:--input:plots} !{output:--output:report}
```

**Benefits**: Debuggable, modular, efficient re-execution, parallelizable.

## 🛠️ Workflow Architecture

### One Workflow Per LAP Class

Each LAP class gets its own workflow script using `argparse` subparsers:

```python
# src/workflows/analysis_workflow.py
def handle_stage_qc(args):
    """Quality control stage"""
    pass

def handle_stage_analyze(args):
    """Main analysis stage"""
    pass

def main():
    parser = argparse.ArgumentParser()
    subparsers = parser.add_subparsers(dest='command')

    # QC stage
    parser_qc = subparsers.add_parser('qc')
    parser_qc.add_argument('--input-file')
    parser_qc.add_argument('--output-file')

    # Analysis stage
    parser_analysis = subparsers.add_parser('analyze')
    # ... define arguments

    args = parser.parse_args()
    if args.command == 'qc':
        handle_stage_qc(args)
    elif args.command == 'analyze':
        handle_stage_analyze(args)
```

### LAP Integration Pattern

Each LAP command maps to exactly one workflow stage:

```cfg
cmd qc_cmd=uv run src/workflows/analysis_workflow.py qc \
    !{input:--input-file:raw_data} \
    !{output:--output-file :qc_results}; \
    class_level analysis

cmd analyze_cmd=uv run src/workflows/analysis_workflow.py analyze \
    !{input:--input-file:qc_results} \
    !{output:--output-file:analysis_results}; \
    class_level analysis
```

## 📚 Documentation

Comprehensive guides are available in the `docs/` directory:

- **[LAP Syntax Guide](docs/LAP_SYNTAX_GUIDE.md)**: Complete reference for LAP configuration and meta file syntax
- **[Workflow Development Guide](docs/WORKFLOW_DEVELOPMENT_GUIDE.md)**: Detailed guide to the opinionated workflow architecture
- **[Template Usage Guide](docs/TEMPLATE_USAGE_GUIDE.md)**: Step-by-step instructions for using this template

## 🎨 Customization Examples

### Adding a New Analysis Type

1. **Add to config file**:
```cfg
class genome_analysis=Genome Analysis parent dataset

path file vcf_file=@genome_analysis.variants.vcf.gz dir analysis_dir
cmd process_vcf_cmd=uv run src/workflows/genome_workflow.py process-vcf \
    --input !{input::vcf_file} --output !{output::results_file}
```

2. **Create workflow script**:
```python
# src/workflows/genome_workflow.py
def handle_process_vcf(args):
    """Process VCF file"""
    # Your VCF processing logic
```

3. **Add instances in meta YAML file**:
```yaml
classes:
  wgs_analysis:
    class: genome_analysis
    parent: my_dataset
    properties:
      vcf_file: "/data/variants.vcf.gz"
```

4. **Generate LAP meta file**:
```bash
meta-sanity generate-meta config/my-project.meta.yaml config/my-project.meta
```

### Integrating External Tools

Wrap external tools in your workflows:

```python
def handle_run_plink(args):
    """Run PLINK analysis"""
    cmd = f"plink --bfile {args.input} --assoc --out {args.output}"
    subprocess.run(cmd, shell=True, check=True)
```

## 🔧 Development Workflow

1. **Plan**: Identify computational steps and data flow
2. **Configure**: Set up LAP classes, files, and commands
3. **Implement**: Create atomic workflow stages
4. **Test**: Validate individual stages and full pipeline
5. **Deploy**: Run production analysis

## 📊 Examples

The template includes examples from real LAP projects:

- **`examples/chase/`**: Clean, readable configurations
- **`examples/jason/`**: Advanced techniques and patterns

Study these to understand different approaches to LAP development.

## 🛡️ Best Practices

- **Atomic Stages**: Each stage should do one logical operation
- **Error Handling**: Validate inputs and handle failures gracefully
- **Logging**: Use structured logging with timestamps
- **Testing**: Test stages individually before integration
- **Documentation**: Document parameters and usage clearly

## 📋 Requirements

- **uv** (for fast Python dependency management) - [Install here](https://github.com/astral-sh/uv)
- **Perl** with Cache::Cache module (for LAP)
- **Python 3.9+** (managed by uv)

All Python dependencies are managed automatically by `uv` via `pyproject.toml`.

## ⚡ UV Fast Python Environment Management

This template uses **uv** for lightning-fast Python dependency management, replacing traditional `pip` and `venv` workflows.

### Why Use UV?

- **10-100x faster** than pip for dependency resolution and installation
- **Zero-config virtual environments** - no need to manually create/activate venvs
- **Lockfile support** for reproducible builds with `uv.lock`
- **Project-based dependency management** with `pyproject.toml`
- **Drop-in replacement** for pip with better caching and parallelization

### UV Workflow:

```bash
# Install all dependencies (creates virtual environment automatically)
uv sync

# Add new dependencies
uv add pandas scipy matplotlib

# Add development dependencies
uv add --dev pytest black flake8

# Run commands in the managed environment
uv run python script.py
uv run pytest tests/
uv run black src/

# Run LAP workflows (automatically uses correct Python environment)
uv run src/workflows/analysis_workflow.py qc --input data.tsv --output qc.json
```

### Optional Dependencies:

Install additional features as needed:

```bash
# For plotting capabilities
uv sync --group plotting

# For statistical analysis
uv sync --group statistics

# For all optional features
uv sync --group all

# Development tools
uv sync --group dev
```

## 🔄 Meta-Sanity Workflow

This template uses **meta-sanity** for managing LAP meta files in YAML format, which is much more readable and maintainable than raw LAP meta files.

### Why Use Meta-Sanity?

- **Readable YAML format** instead of tab-delimited meta files
- **Template system** for generating multiple similar instances
- **Variable substitution** with `${variable}` syntax
- **Validation** of meta file structure
- **Documentation** within the YAML file itself

### Basic Workflow:

```bash
# 1. Edit your YAML meta file
nano config/my-project.meta.yaml

# 2. Generate traditional LAP meta file
meta-sanity generate-meta config/my-project.meta.yaml config/my-project.meta

# 3. Run LAP pipeline as usual
perl lap-src/trunk/bin/run.pl --meta config/my-project.meta
```

### Template Examples in starter.meta.yaml:

```yaml
# Generate multiple trait analyses
trait_analyses:
  class: analysis
  operation: for_each_item
  input: [trait_001, trait_002, trait_003]
  pattern:
    name: "analysis_${item}"
    parent: main_study
    properties:
      trait_name: "${item}"

# Combinatorial analysis across methods and datasets
method_combinations:
  class: analysis
  operation: iter.combination
  input:
    - name: method
      values: ["linear_regression", "random_forest"]
    - name: dataset
      values: ["pilot_study", "main_study"]
  pattern:
    name: "${item:method}__${item:dataset}"
```

## 🤝 Contributing

This template is designed to be a starting point. Customize it for your specific analysis needs:

1. Fork/clone this repository
2. Modify configurations for your analysis
3. Implement your domain-specific workflows
4. Share improvements back to the community

## 📄 License

This template is provided as-is for research and educational use. LAP itself is developed by Jason Flannick and collaborators.

## 🆘 Getting Help

- Review the comprehensive documentation in `docs/`
- Study the example configurations in `examples/`
- Check LAP syntax in existing working pipelines
- Ask questions about specific LAP features or configuration issues

---

**Happy LAP Pipeline Development! 🚀**
